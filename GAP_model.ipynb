{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2FaUTJSGUE/SZeIGMEvJI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baptonx7/enduraw-case-study/blob/main/GAP_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gpxpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_4qZzcT6Wf6",
        "outputId": "e9183d98-7515-44de-c753-5c348106393b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gpxpy\n",
            "  Downloading gpxpy-1.6.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Downloading gpxpy-1.6.2-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gpxpy\n",
            "Successfully installed gpxpy-1.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gpxpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# 1) Load GPX geometry\n",
        "with open(\"Lahti_run.gpx\", \"r\") as f:\n",
        "    gpx = gpxpy.parse(f)\n",
        "\n",
        "points = []\n",
        "for track in gpx.tracks:\n",
        "    for seg in track.segments:\n",
        "        for p in seg.points:\n",
        "            points.append({'lat': p.latitude, 'lon': p.longitude, 'ele': p.elevation})\n",
        "df_gpx = pd.DataFrame(points)\n",
        "\n",
        "# 2) Load split times from CSV\n",
        "df_splits = pd.read_csv(\"Amelia Watkinson - Run-splits CSV.csv\")\n",
        "\n",
        "# Expecting columns like: \"km\",\"split_time\"\n",
        "# Make sure split_time is in seconds, otherwise convert\n",
        "# Example if format is \"mm:ss\":\n",
        "def time_to_sec(x):\n",
        "    parts = str(x).split(\":\")\n",
        "    if len(parts) == 2:\n",
        "        return int(parts[0])*60 + int(parts[1])\n",
        "    elif len(parts) == 3:\n",
        "        return int(parts[0])*3600 + int(parts[1])*60 + int(parts[2])\n",
        "    else:\n",
        "        return float(x)\n",
        "\n",
        "df_splits['time_s'] = df_splits['split_time'].apply(time_to_sec)\n",
        "\n",
        "# 3) Compute cumulative distance from GPX\n",
        "def haversine_m(lat1, lon1, lat2, lon2):\n",
        "    R = 6371000.0\n",
        "    phi1, phi2 = math.radians(lat1), math.radians(lat2)\n",
        "    dphi = math.radians(lat2 - lat1)\n",
        "    dlambda = math.radians(lon2 - lon1)\n",
        "    a = math.sin(dphi/2.0)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlambda/2.0)**2\n",
        "    return R * 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
        "\n",
        "distances = [0.0]\n",
        "for i in range(1, len(df_gpx)):\n",
        "    d = haversine_m(df_gpx.loc[i-1,'lat'], df_gpx.loc[i-1,'lon'],\n",
        "                    df_gpx.loc[i,'lat'], df_gpx.loc[i,'lon'])\n",
        "    distances.append(d)\n",
        "df_gpx['d_m'] = distances\n",
        "df_gpx['cum_m'] = df_gpx['d_m'].cumsum()\n",
        "\n",
        "# 4) Compute grade per km\n",
        "km_bins = np.arange(1000, df_gpx['cum_m'].iloc[-1]+1000, 1000)\n",
        "elev_changes, grades = [], []\n",
        "for km in km_bins:\n",
        "    mask = df_gpx['cum_m'] <= km\n",
        "    elev = df_gpx.loc[mask, 'ele'].iloc[-1]\n",
        "    if len(elev_changes)==0:\n",
        "        elev_changes.append(0)\n",
        "    else:\n",
        "        elev_changes.append(elev - prev_elev)\n",
        "    prev_elev = elev\n",
        "grades = [ec/1000 for ec in elev_changes]  # grade = elev gain / horiz dist\n",
        "\n",
        "# 5) Merge geometry + splits\n",
        "df_splits['elev_change_m'] = elev_changes[:len(df_splits)]\n",
        "df_splits['grade_frac'] = df_splits['elev_change_m']/1000.0\n",
        "df_splits['pace_s_per_km'] = df_splits['time_s']  # since each split = 1 km\n",
        "\n",
        "# 6) Apply simple GAP model\n",
        "def gap_multiplier_simple(grade_percent, k_up=10.0, k_down=4.0):\n",
        "    if grade_percent >= 0:\n",
        "        return 1.0 + (k_up * grade_percent / 100.0)\n",
        "    else:\n",
        "        return max(0.7, 1.0 + (-k_down * abs(grade_percent) / 100.0))\n",
        "\n",
        "df_splits['gap_pace_s_per_km'] = df_splits.apply(\n",
        "    lambda r: r['pace_s_per_km'] / gap_multiplier_simple(r['grade_frac']*100),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# 7) Output results\n",
        "df_splits['pace_min_per_km'] = df_splits['pace_s_per_km']/60\n",
        "df_splits['gap_min_per_km'] = df_splits['gap_pace_s_per_km']/60\n",
        "\n",
        "print(df_splits[['km','pace_min_per_km','gap_min_per_km','grade_frac']].head())\n",
        "\n",
        "# Save to CSV\n",
        "df_splits.to_csv(\"gpx_gap_splits.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5e6umqz9DHM",
        "outputId": "2278a736-b352-4105-9686-e64f9c9ca455"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    km  pace_min_per_km  gap_min_per_km  grade_frac\n",
            "0  0.4         1.783333        1.783333      0.0000\n",
            "1  1.0         3.716667        2.845840      0.0306\n",
            "2  1.2         5.116667        4.520024      0.0132\n",
            "3  1.4         5.350000        5.397498     -0.0022\n",
            "4  1.3         4.566667        5.161242     -0.0288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gpxpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "gpx_file = \"70.3WC Marbella Run Course.gpx\"\n",
        "target_gap_pace = 227          # target GAP in sec/km (e.g. 227 = 3:47/km)\n",
        "segment_length = 500           # pacing plan resolution in meters\n",
        "\n",
        "# 1) Parse GPX\n",
        "with open(gpx_file, 'r') as f:\n",
        "    gpx = gpxpy.parse(f)\n",
        "\n",
        "distances = [0.0]\n",
        "elevations = []\n",
        "\n",
        "prev_point = None\n",
        "for track in gpx.tracks:\n",
        "    for segment in track.segments:\n",
        "        for point in segment.points:\n",
        "            if prev_point is not None:\n",
        "                d = point.distance_3d(prev_point)\n",
        "                distances.append(distances[-1] + d)\n",
        "            elevations.append(point.elevation)\n",
        "            prev_point = point\n",
        "\n",
        "# Make dataframe\n",
        "df = pd.DataFrame({\n",
        "    \"distance\": distances[:len(elevations)],\n",
        "    \"elevation\": elevations\n",
        "})\n",
        "\n",
        "# 2) Smooth elevation (moving average)\n",
        "df[\"elev_smooth\"] = df[\"elevation\"].rolling(window=5, center=True, min_periods=1).mean()\n",
        "\n",
        "# 3) Compute slope\n",
        "df[\"slope\"] = df[\"elev_smooth\"].diff().fillna(0) / df[\"distance\"].diff().replace(0, np.nan).fillna(1)\n",
        "\n",
        "# 4) GAP model\n",
        "# Simple model: slope to pace multiplier\n",
        "def gap_multiplier_simple(slope):\n",
        "    # slope in %\n",
        "    s = slope * 100\n",
        "    if s > 10:\n",
        "        s = 10\n",
        "    if s < -10:\n",
        "        s = -10\n",
        "    return 1 + 0.03 * s  # +3% pace per +1% slope\n",
        "\n",
        "# Convert slope to actual pace (sec/km)\n",
        "df[\"pace\"] = target_gap_pace * df[\"slope\"].apply(gap_multiplier_simple)\n",
        "\n",
        "# 5) Aggregate into 500m segments\n",
        "segments = []\n",
        "max_dist = df[\"distance\"].iloc[-1]\n",
        "cumulative_time_sec = 0\n",
        "\n",
        "for start in np.arange(0, max_dist, segment_length):\n",
        "  end = min(start + segment_length, max_dist)\n",
        "  mask = (df[\"distance\"] >= start) & (df[\"distance\"] < end)\n",
        "  if mask.sum() > 0:\n",
        "    avg_slope = df.loc[mask, \"slope\"].mean()\n",
        "    avg_pace = df.loc[mask, \"pace\"].mean()\n",
        "    dist_km = (end - start) / 1000\n",
        "    seg_time = dist_km * avg_pace\n",
        "    cumulative_time_sec += seg_time\n",
        "    hours = int(cumulative_time_sec // 3600)\n",
        "    minutes = int((cumulative_time_sec % 3600) // 60)\n",
        "    seconds = int(cumulative_time_sec % 60)\n",
        "    cum_time_str = f\"{hours}:{minutes:02d}:{seconds:02d}\"\n",
        "    segments.append({\n",
        "      \"start_m\": int(start),\n",
        "      \"end_m\": int(end),\n",
        "      \"avg_slope_%\": round(avg_slope*100,2),\n",
        "      \"target_pace_sec_per_km\": int(avg_pace),\n",
        "      \"target_pace_min_per_km\": f\"{int(avg_pace//60)}:{int(avg_pace%60):02d}\",\n",
        "      \"Total_predicted_time\": cum_time_str\n",
        "  })\n",
        "\n",
        "pace_plan = pd.DataFrame(segments)\n",
        "\n",
        "# 6) Export\n",
        "pace_plan.to_csv(\"pacing_plan.csv\", index=False)\n",
        "\n",
        "print(pace_plan.head())\n",
        "print(f\"Predicted total race time: {pace_plan['Total_predicted_time'].iloc[-1]}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSfxgg9sesZZ",
        "outputId": "92b3a8a5-b6d5-4c51-8b60-b8002937aaa4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   start_m  end_m  avg_slope_%  target_pace_sec_per_km target_pace_min_per_km  \\\n",
            "0        0    500        -3.31                     230                   3:50   \n",
            "1      500   1000        -1.95                     213                   3:33   \n",
            "2     1000   1500        -0.37                     224                   3:44   \n",
            "3     1500   2000        -0.32                     224                   3:44   \n",
            "4     2000   2500         0.07                     227                   3:47   \n",
            "\n",
            "  Total_predicted_time  \n",
            "0              0:01:55  \n",
            "1              0:03:42  \n",
            "2              0:05:34  \n",
            "3              0:07:26  \n",
            "4              0:09:20  \n",
            "Predicted total race time: 1:19:24\n"
          ]
        }
      ]
    }
  ]
}
